# VPetLLM 插件功能增强与重构说明文档

**致 VPetLLM 原作者：**

您好！

本文档详细记录了近期对 VPetLLM 插件进行的一系列重要功能增强和代码重构。所有修改都旨在全面提升插件的**长期记忆能力**、**API交互的稳定性与健壮性**，以及**代码的整体质量**。

希望这份详尽的报告能帮助您了解我们所做的改进，并为插件的未来发展提供参考。

---

## I. 核心新增功能：可持久化的动态长期记忆系统

我们从零开始设计并实现了一套全新的长期记忆系统，它允许桌宠（AI）在多次程序重启之间保持关键记忆，并能随着与用户的互动不断迭代和优化这份记忆。

### 1. 功能概述

- **持久化存储**：记忆被保存在一个独立的文本文件 (`.memory.txt`) 中，与聊天记录并存，程序重启后会自动加载。
- **智能迭代**：当短期对话达到一定长度时，系统会将“旧的记忆”和“新的对话”一同提交给 AI，由 AI 进行融合、提炼和修正，生成一份更完善的新版记忆。
- **可控上限**：记忆的总长度（Token数量）拥有可配置的上限，AI 在生成新记忆时会遵守此限制，防止记忆无限膨胀。
- **UI配置**：用户可以在设置界面的“高级选项”中，方便地开启/关闭此功能，并自由设定记忆的触发阈值和上限。

### 2. 代码实现细节

- **配置文件 (`Setting.cs`)**: 添加了 `LongTermMemoryTokenLimit` 属性来定义记忆的Token上限。
- **记忆文件管理 (`Core/HistoryManager.cs`)**: 新增了 `LongTermMemoryFilePath` 属性，用于定义和管理 `.memory.txt` 文件的路径。
- **核心逻辑 (`Core/ChatCoreBase.cs`)**: 
    1.  **加载**：在构造函数中增加了启动时自动从文件加载记忆的逻辑。
    2.  **注入**：重构了 `GetSystemMessage` 方法，将长期记忆作为背景信息附加到主系统提示词之前。
    3.  **迭代与保存**：重写了 `CheckAndSummarizeHistoryIfNeeded` 方法，实现了“修正与补充”的核心逻辑，并在生成新记忆后将其写入文件。
- **AI指令更新 (`Core/ChatCore/*.cs`)**: 更新了 `Summarize` 方法中的提示词，明确指导AI扮演“记忆编辑器”的角色，并使其遵守Token上限。

---

## II. API交互与核心稳定性增强

为了提高插件在面对网络波动和API限制时的表现，我们引入了一套更强大的API请求处理机制。

### 1. API密钥轮询机制

- **目的**：支持用户在设置中输入多个API Key（换行分隔），程序会在每次请求时自动轮换使用，有效分散单个Key的请求频率，或在某个Key失效/超额时自动切换到下一个。
- **实现**：在各 `ChatCore` 中新增 `GetNextApiKey()` 方法，通过静态索引和取模运算实现循环获取。

### 2. 可配置的客户端速率限制

- **目的**：遵循上游API的TPM（Tokens-Per-Minute）和RPM（Requests-Per-Minute）规范，避免因请求过快而被封禁，并允许用户根据自己的API额度进行自定义。
- **实现**：
    - 在 `Setting.cs` 中新增了 `RateLimiterSettings` 类，包含 `IsEnabled`, `TpmLimitPerKey`, `RpmLimitPerKey` 属性。
    - 重构了 `Utils/RateLimiter.cs`，使其不再使用硬编码值，而是从传入的 `RateLimiterSettings` 对象中动态读取限制参数。
    - 更新了所有 `ChatCore` 中对 `RateLimiter.WaitForReady` 的调用，将新的设置对象传递进去。

### 3. 指数退避与自动重试

- **目的**：当收到API返回的 `429 Too Many Requests` 错误或其他网络异常时，程序不会立即失败，而是会进行多次自动重试。
- **实现**：新增了 `SendRequestWithRetry` 方法封装所有网络请求。当捕获到 `429` 状态码时，采用指数退避策略增加等待间隔，并结合密钥轮询，实现故障的快速转移。

### 4. UI死锁防治

- **目的**：避免在UI线程上等待异步网络请求完成时可能导致的界面卡死（Deadlock）。
- **实现**：在项目的所有 `async` 方法中，对 `await` 的调用都添加了 `.ConfigureAwait(false)`，强制异步任务在后台线程上恢复，从而释放UI线程。

---

## III. UI/UX 改进

- **新增“长期记忆”设置**：在“高级选项”中，添加了“启用自动对话历史摘要”的开关，以及“摘要触发阈值”和“长期记忆上限”的输入框，所有选项均支持实时修改和自动保存。
- **新增“API速率限制”设置**：同样在“高级选项”中，为速率限制功能添加了总开关，以及TPM和RPM的参数输入框，使用户可以完全控制API请求频率。

---

## IV. Bug 修复与其他改进

1.  **项目配置修复**：修复了 `.csproj` 文件会将 `VPetLLM源代码` 目录下的原始文件一并编译，从而导致大量“重复定义”的编译错误的问题。
2.  **API逻辑修复 (Gemini)**：
    - **`contents is not specified` 错误**：调整了 `Chat` 方法的执行顺序，确保总结操作在添加新消息之前执行，避免当前输入被错误清除。
    - **“记忆丢失”漏洞**：重构了 `Chat` 方法，删除了冗余的 `GetCoreHistory` 方法，修复了因 `GetSystemMessage` 被不当调用两次而导致记忆被意外清除的逻辑缺陷。
    - **历史记录清理**：重写了 `SanitizeHistory` 方法，使其更严格地遵循Gemini API关于角色交替的规范。
3.  **修复了 `Setting.cs` 的编译错误**：
    - **问题**：在一次文件写入操作中，`DIYTTSSetting` 类中的 `RequestBody` 字符串因转义问题被破坏。
    - **修复**：使用了C#的 `"@..."` (verbatim string) 语法重写了该字符串，使其更健壮，不易出错。

4.  **修复 API 返回空内容时导致的 `NullReferenceException` 崩溃**：
    - **问题**：在 `GeminiChatCore` 和 `OpenAIChatCore` 中，代码在解析 API 响应时，没有考虑到当 API 因为内容安全策略等原因返回一个空的成功响应时，回复的 `candidates` 或 `choices` 数组可能不存在，从而导致程序因“对象引用未设置为对象的实例”而崩溃。
    - **修复**：使用了 C# 的 null 条件运算符 (`?.`) 和 `FirstOrDefault()` 来安全地、逐层地访问 JSON 对象的属性。增加了对返回内容是否为空的检查，如果为空，则记录原因并向用户返回一个友好的提示，而不是让程序崩溃。

---

我们相信，以上所有修改的结合，不仅为VPetLLM带来了强大的、真正的长期记忆能力，也使其变得更加稳定、可靠和智能。希望这些工作能对您有所帮助。

祝好！
